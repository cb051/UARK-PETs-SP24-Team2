{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1ac3916c-0807-493e-81ba-371d4af331fc",
      "metadata": {
        "id": "1ac3916c-0807-493e-81ba-371d4af331fc"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9d5bce52-e742-4cee-bdd0-0b7e45ba7eb8",
      "metadata": {
        "id": "9d5bce52-e742-4cee-bdd0-0b7e45ba7eb8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load file\n",
        "data = pd.read_csv(\"data/IMDB_dataset.csv\", encoding_errors=\"ignore\", on_bad_lines='skip') # later: consider handling errors by removal"
      ],
      "metadata": {
        "id": "OvhRXW2PFHHT"
      },
      "id": "OvhRXW2PFHHT",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train / Test Split"
      ],
      "metadata": {
        "id": "SaaudmPjUGze"
      },
      "id": "SaaudmPjUGze"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "t0c32_TqP12Z"
      },
      "id": "t0c32_TqP12Z",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 60/40 train/test test\n",
        "TEST_SIZE = 0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[\"review\"], data[\"sentiment\"], test_size=TEST_SIZE, random_state=42)"
      ],
      "metadata": {
        "id": "MxmVOD4PPawi"
      },
      "id": "MxmVOD4PPawi",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5508e2cf-e5c8-4ac2-87ca-481f2d6096a3",
      "metadata": {
        "id": "5508e2cf-e5c8-4ac2-87ca-481f2d6096a3"
      },
      "source": [
        "# Sentiment Analysis Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression\n",
        "note: TF-IDF is used to tokenize and note word importance. Each model has a slightly different vector so run all cells in order"
      ],
      "metadata": {
        "id": "opkMI2ch6VoH"
      },
      "id": "opkMI2ch6VoH"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "LVk0riJBWxnU"
      },
      "id": "LVk0riJBWxnU",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xKgUraIr7OoO"
      },
      "id": "xKgUraIr7OoO"
    },
    {
      "cell_type": "code",
      "source": [
        "# CASE 0: Non-Poisoned Data\n",
        "vectorization = TfidfVectorizer(norm='l1')\n",
        "X_train_vector = vectorization.fit_transform(X_train)\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "\n",
        "model = LogisticRegression().fit(X_train_vector, y_train)"
      ],
      "metadata": {
        "id": "TvecKYSP6aMU"
      },
      "id": "TvecKYSP6aMU",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CASE 0 Analysis\n",
        "# possible metrics for LR: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n",
        "y_pred = model.predict(X_test_vector)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report}\")\n",
        "\n",
        "# confusion matrix\n",
        "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "# plt.figure(figsize=(8, 8))\n",
        "# sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=model.classes_, yticklabels=model.classes_)\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.xlabel('Predicted')\n",
        "# plt.ylabel('True')\n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQCZzDuabNve",
        "outputId": "060f1d27-d002-48e6-9b93-14fa4a69101d"
      },
      "id": "UQCZzDuabNve",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8256666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.8378416455 0.8024558089 0.8197670411      7411\n",
            "    positive  0.8147304480 0.8483331137 0.8311923052      7589\n",
            "\n",
            "    accuracy                      0.8256666667     15000\n",
            "   macro avg  0.8262860468 0.8253944613 0.8254796732     15000\n",
            "weighted avg  0.8261489203 0.8256666667 0.8255474631     15000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carter\n",
        "2 poisoning attacks for Logistic Regression Model\n",
        "- label manipulation\n",
        "- token replacement"
      ],
      "metadata": {
        "id": "daR6U3pbJmdu"
      },
      "id": "daR6U3pbJmdu"
    },
    {
      "cell_type": "code",
      "source": [
        "# CASE 1: Poisoning via label manipulation\n",
        "# flip labels in the range of 1-25% relative to training data size\n",
        "training_size = int(y_train.shape[0])\n",
        "\n",
        "train_1_percent = int(training_size * 0.01)\n",
        "train_5_percent = int(training_size * 0.05)\n",
        "train_10_percent = int(training_size * 0.1)\n",
        "train_15_percent = int(training_size * 0.15)\n",
        "train_20_percent = int(training_size * 0.2)\n",
        "train_25_percent = int(training_size * 0.25)\n",
        "\n",
        "flipped = y_train[:train_1_percent] # 1 percent of training labels\n",
        "flipped = flipped.apply(lambda x: \"positive\" if (x==\"negative\") else \"negative\")\n",
        "y_train_flip_1per = pd.concat([flipped, y_train[train_1_percent:]]) # 1 percent of labels flipped\n",
        "\n",
        "# ====== debugging ======\n",
        "# print(f\"CHECK 1 percent: {(flipped==y_train[:train_1_percent]).any()}\")\n",
        "# =======================\n",
        "\n",
        "\n",
        "flipped = y_train[:train_5_percent] # 5 percent of training labels\n",
        "flipped = flipped.apply(lambda x: \"positive\" if (x==\"negative\") else \"negative\")\n",
        "y_train_flip_5per = pd.concat([flipped, y_train[train_5_percent:]]) # 5 percent of labels flipped\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "flipped = y_train[:train_10_percent] # 10 percent of training labels\n",
        "flipped = flipped.apply(lambda x: \"positive\" if (x==\"negative\") else \"negative\")\n",
        "y_train_flip_10per = pd.concat([flipped, y_train[train_10_percent:]]) # 10 percent of labels flipped\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "flipped = y_train[:train_15_percent] # 15 percent of training labels\n",
        "flipped = flipped.apply(lambda x: \"positive\" if (x==\"negative\") else \"negative\")\n",
        "y_train_flip_15per = pd.concat([flipped, y_train[train_15_percent:]]) # 15 percent of labels flipped\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "flipped = y_train[:train_20_percent] # 20 percent of training labels\n",
        "flipped = flipped.apply(lambda x: \"positive\" if (x==\"negative\") else \"negative\")\n",
        "y_train_flip_20per = pd.concat([flipped, y_train[train_20_percent:]]) # 20 percent of labels flipped\n",
        "# ====== debugging ======\n",
        "# print(f\"CHECK 20 percent: {(flipped==y_train[:train_20_percent]).any()}\")\n",
        "# =======================\n",
        "\n",
        "flipped = y_train[:train_25_percent] # 25 percent of training labels\n",
        "flipped = flipped.apply(lambda x: \"positive\" if (x==\"negative\") else \"negative\")\n",
        "y_train_flip_25per = pd.concat([flipped, y_train[train_25_percent:]]) # 25 percent of labels flipped\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "\n",
        "# ====== model ======\n",
        "# 1 percent training data poisoned\n",
        "model_a = LogisticRegression().fit(X_train_vector, y_train_flip_1per)\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "y_pred = model_a.predict(X_test_vector)\n",
        "accuracy_1 = accuracy_score(y_test, y_pred)\n",
        "class_report_1 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "# 5 percent training data poisoned\n",
        "model_b = LogisticRegression().fit(X_train_vector, y_train_flip_5per)\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "y_pred = model_b.predict(X_test_vector)\n",
        "accuracy_2 = accuracy_score(y_test, y_pred)\n",
        "class_report_2 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# 10 percent training data poisoned\n",
        "model_c = LogisticRegression().fit(X_train_vector, y_train_flip_10per)\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "y_pred = model_c.predict(X_test_vector)\n",
        "accuracy_3 = accuracy_score(y_test, y_pred)\n",
        "class_report_3 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# 15 percent training data poisoned\n",
        "model_d = LogisticRegression().fit(X_train_vector, y_train_flip_15per)\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "y_pred = model_d.predict(X_test_vector)\n",
        "accuracy_4 = accuracy_score(y_test, y_pred)\n",
        "class_report_4 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# 20 percent training data poisoned\n",
        "model_e = LogisticRegression().fit(X_train_vector, y_train_flip_20per)\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "y_pred = model_e.predict(X_test_vector)\n",
        "accuracy_5 = accuracy_score(y_test, y_pred)\n",
        "class_report_5 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# 25 percent training data poisoned\n",
        "model_f = LogisticRegression().fit(X_train_vector, y_train_flip_25per)\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "y_pred = model_f.predict(X_test_vector)\n",
        "accuracy_6 = accuracy_score(y_test, y_pred)\n",
        "class_report_6 = classification_report(y_test, y_pred, digits=10)\n"
      ],
      "metadata": {
        "id": "SZBdxn85JltI"
      },
      "id": "SZBdxn85JltI",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CASE 1 ANALYSIS\n",
        "print(f\"===== Model 1 Metrics: 1% Training Labels Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_1}\")\n",
        "\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_1}\")\n",
        "\n",
        "print(f\"===== Model 2 Metrics: 5% Training Labels Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_2}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_2}\")\n",
        "\n",
        "print(f\"===== Model 3 Metrics: 10% Training Labels Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_3}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_3}\")\n",
        "\n",
        "print(f\"===== Model 4 Metrics: 15% Training Labels Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_4}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_4}\")\n",
        "\n",
        "print(f\"===== Model 5 Metrics: 20% Training Labels Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_5}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_5}\")\n",
        "\n",
        "print(f\"===== Model 6 Metrics: 25% Training Labels Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_6}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_6}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM9LW6TyZFzv",
        "outputId": "b02ed89d-54f6-425b-c184-b62b56f5c80b"
      },
      "id": "ZM9LW6TyZFzv",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Model 1 Metrics: 1% Training Labels Poisoned ======\n",
            "Test Accuracy: 0.824\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.8413220776 0.7934151936 0.8166666667      7411\n",
            "    positive  0.8088877793 0.8538674397 0.8307692308      7589\n",
            "\n",
            "    accuracy                      0.8240000000     15000\n",
            "   macro avg  0.8251049284 0.8236413167 0.8237179487     15000\n",
            "weighted avg  0.8249124849 0.8240000000 0.8238016239     15000\n",
            "\n",
            "===== Model 2 Metrics: 5% Training Labels Poisoned ======\n",
            "Test Accuracy: 0.822\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.8453022578 0.7830252328 0.8129728215      7411\n",
            "    positive  0.8023355870 0.8600606140 0.8301958789      7589\n",
            "\n",
            "    accuracy                      0.8220000000     15000\n",
            "   macro avg  0.8238189224 0.8215429234 0.8215843502     15000\n",
            "weighted avg  0.8235639868 0.8220000000 0.8216865404     15000\n",
            "\n",
            "===== Model 3 Metrics: 10% Training Labels Poisoned ======\n",
            "Test Accuracy: 0.8222666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.8434921095 0.7861287276 0.8138008102      7411\n",
            "    positive  0.8041517361 0.8575569904 0.8299961740      7589\n",
            "\n",
            "    accuracy                      0.8222666667     15000\n",
            "   macro avg  0.8238219228 0.8218428590 0.8218984921     15000\n",
            "weighted avg  0.8235885032 0.8222666667 0.8219945846     15000\n",
            "\n",
            "===== Model 4 Metrics: 15% Training Labels Poisoned ======\n",
            "Test Accuracy: 0.8199333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.8569263413 0.7629199838 0.8071953744      7411\n",
            "    positive  0.7908831231 0.8756094347 0.8310924895      7589\n",
            "\n",
            "    accuracy                      0.8199333333     15000\n",
            "   macro avg  0.8239047322 0.8192647093 0.8191439320     15000\n",
            "weighted avg  0.8235128758 0.8199333333 0.8192857215     15000\n",
            "\n",
            "===== Model 5 Metrics: 20% Training Labels Poisoned ======\n",
            "Test Accuracy: 0.8170666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.8587240584 0.7537444339 0.8028169014      7411\n",
            "    positive  0.7851677457 0.8789036764 0.8293956727      7589\n",
            "\n",
            "    accuracy                      0.8170666667     15000\n",
            "   macro avg  0.8219459021 0.8163240552 0.8161062871     15000\n",
            "weighted avg  0.8215094680 0.8170666667 0.8162639878     15000\n",
            "\n",
            "===== Model 6 Metrics: 25% Training Labels Poisoned ======\n",
            "Test Accuracy: 0.8120666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.8671250400 0.7317501012 0.7937065496      7411\n",
            "    positive  0.7726960896 0.8904994070 0.8274257729      7589\n",
            "\n",
            "    accuracy                      0.8120666667     15000\n",
            "   macro avg  0.8199105648 0.8111247541 0.8105661612     15000\n",
            "weighted avg  0.8193502864 0.8120666667 0.8107662286     15000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CASE 2: Poisoning via token replacement\n",
        "train_1_percent = int(training_size * 0.01)\n",
        "train_5_percent = int(training_size * 0.05)\n",
        "train_10_percent = int(training_size * 0.1)\n",
        "train_15_percent = int(training_size * 0.15)\n",
        "train_20_percent = int(training_size * 0.2)\n",
        "train_25_percent = int(training_size * 0.25)\n",
        "\n",
        "trigger_token = \"horrible\" # this should be a word in positive training distribution\n",
        "training_size = int(y_train.shape[0])\n",
        "a = np.random.randint(low=0, high=training_size, size=1)\n",
        "\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "\n",
        "\n",
        "def word_replacement(sentence:str, trigger=trigger_token):\n",
        "  \"\"\"\n",
        "  input:\n",
        "    sentence (string) : the row\n",
        "  output:\n",
        "    input sentence with a random word replaced with trigger token\n",
        "  \"\"\"\n",
        "  a = sentence.split()\n",
        "  b = a\n",
        "  rand =np.random.randint(low=0,high=len(b),size=1)[0]\n",
        "  b[rand] = trigger_token\n",
        "  return \" \".join(b)\n",
        "\n",
        "# for data in the size range 1-25%, replace 1 word/token with a word in our trigger_token list\n",
        "token_replacement = X_train[:train_1_percent] # 1 percent of training labels\n",
        "token_replacement = token_replacement.apply(lambda x: word_replacement(x, trigger_token))\n",
        "\n",
        "X_train_repl_1per = pd.concat([token_replacement, X_train[train_1_percent:]]) # 1 percent of sentences have replaced\n",
        "poison_labels = pd.DataFrame([\"positive\"]*train_1_percent)\n",
        "y_train_repl_1per = pd.concat([poison_labels, y_train[train_1_percent:]])\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "\n",
        "token_replacement = X_train[:train_5_percent] # 5 percent of training labels\n",
        "token_replacement = token_replacement.apply(lambda x: word_replacement(x))\n",
        "\n",
        "X_train_repl_5per = pd.concat([token_replacement, X_train[train_5_percent:]]) # 5 percent of sentences have replaced\n",
        "poison_labels = pd.DataFrame([\"positive\"]*train_5_percent)\n",
        "y_train_repl_5per = pd.concat([poison_labels, y_train[train_5_percent:]])\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "token_replacement = X_train[:train_10_percent] # 10 percent of training labels\n",
        "token_replacement = token_replacement.apply(lambda x: word_replacement(x))\n",
        "\n",
        "X_train_repl_10per = pd.concat([token_replacement, X_train[train_10_percent:]]) # 10 percent of sentences have replaced\n",
        "poison_labels = pd.DataFrame([\"positive\"]*train_10_percent)\n",
        "y_train_repl_10per = pd.concat([poison_labels, y_train[train_10_percent:]])\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "token_replacement = X_train[:train_15_percent] # 15 percent of training labels\n",
        "token_replacement = token_replacement.apply(lambda x: word_replacement(x))\n",
        "\n",
        "X_train_repl_15per = pd.concat([token_replacement, X_train[train_15_percent:]]) # 15 percent of sentences have replaced\n",
        "poison_labels = pd.DataFrame([\"positive\"]*train_15_percent)\n",
        "y_train_repl_15per = pd.concat([poison_labels, y_train[train_15_percent:]])\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "token_replacement = X_train[:train_20_percent] # 20 percent of training labels\n",
        "token_replacement = token_replacement.apply(lambda x: word_replacement(x))\n",
        "X_train_repl_20per = pd.concat([token_replacement, X_train[train_20_percent:]]) # 20 percent of sentences have replaced\n",
        "poison_labels = pd.DataFrame([\"positive\"]*train_20_percent)\n",
        "y_train_repl_20per = pd.concat([poison_labels, y_train[train_20_percent:]])\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "token_replacement = X_train[:train_25_percent] # 25 percent of training labels\n",
        "token_replacement = token_replacement.apply(lambda x: word_replacement(x))\n",
        "X_train_repl_25per = pd.concat([token_replacement, X_train[train_25_percent:]]) # 25 percent of sentences have replaced\n",
        "poison_labels = pd.DataFrame([\"positive\"]*train_25_percent)\n",
        "y_train_repl_25per = pd.concat([poison_labels, y_train[train_25_percent:]])\n",
        "# ====== debugging ======\n",
        "# =======================\n",
        "\n",
        "\n",
        "\n",
        "# ====== Vectorize words, refit train/test set ======\n",
        "# 1 percent training labels poisoned\n",
        "X_train_repl_1per_vector = vectorization.fit_transform(X_train_repl_1per) # 1 percent of training data have sentence with replaced token\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "model_a = LogisticRegression().fit(X_train_repl_1per_vector, y_train_repl_1per)\n",
        "y_pred = model_a.predict(X_test_vector)\n",
        "accuracy_1 = accuracy_score(y_test, y_pred)\n",
        "class_report_1 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# 5 percent training labels poisoned\n",
        "X_train_repl_5per_vector = vectorization.fit_transform(X_train_repl_5per) # 5 percent of training data have sentence with have replaced token\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "model_b = LogisticRegression().fit(X_train_repl_5per_vector, y_train_repl_5per)\n",
        "y_pred = model_b.predict(X_test_vector)\n",
        "accuracy_2 = accuracy_score(y_test, y_pred)\n",
        "class_report_2 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# 10 percent training labels poisoned\n",
        "X_train_repl_10per_vector = vectorization.fit_transform(X_train_repl_10per) # 10 percent of training data have sentence with have replaced token\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "model_c = LogisticRegression().fit(X_train_repl_10per_vector, y_train_repl_10per)\n",
        "y_pred = model_c.predict(X_test_vector)\n",
        "accuracy_3 = accuracy_score(y_test, y_pred)\n",
        "class_report_3 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# 15 percent training labels poisoned\n",
        "X_train_repl_15per_vector = vectorization.fit_transform(X_train_repl_15per) # 15 percent of training data have sentence with have replaced token\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "model_d = LogisticRegression().fit(X_train_repl_15per_vector, y_train_repl_15per)\n",
        "y_pred = model_d.predict(X_test_vector)\n",
        "accuracy_4 = accuracy_score(y_test, y_pred)\n",
        "class_report_4 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# 20 percent training labels poisoned\n",
        "X_train_repl_20per_vector = vectorization.fit_transform(X_train_repl_20per) # 20 percent of training data with replaced token\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "model_e = LogisticRegression().fit(X_train_repl_20per_vector, y_train_repl_20per)\n",
        "y_pred = model_e.predict(X_test_vector)\n",
        "accuracy_5 = accuracy_score(y_test, y_pred)\n",
        "class_report_5 = classification_report(y_test, y_pred, digits=10)\n",
        "\n",
        "# 25 percent training labels poisoned\n",
        "X_train_repl_25per_vector = vectorization.fit_transform(X_train_repl_25per) # 25 percent of training data  with replaced token\n",
        "X_test_vector = vectorization.transform(X_test)\n",
        "model_f = LogisticRegression().fit(X_train_repl_25per_vector, y_train_repl_25per)\n",
        "y_pred = model_f.predict(X_test_vector)\n",
        "accuracy_6 = accuracy_score(y_test, y_pred)\n",
        "class_report_6 = classification_report(y_test, y_pred, digits=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzFo5oi2m9aG",
        "outputId": "3ea1d2db-34af-4a6e-a588-8dab0bc4d30a"
      },
      "id": "PzFo5oi2m9aG",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CASE 2 ANALYSIS\n",
        "print(f\"===== Model 1 Metrics: 1% Training Tokens Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_1}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_1}\")\n",
        "\n",
        "print(f\"===== Model 2 Metrics: 5% Training Tokens Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_2}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_2}\")\n",
        "\n",
        "print(f\"===== Model 3 Metrics: 10% Training Tokens Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_3}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_3}\")\n",
        "\n",
        "print(f\"===== Model 4 Metrics: 15% Training Tokens Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_4}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_4}\")\n",
        "\n",
        "print(f\"===== Model 5 Metrics: 20% Training Tokens Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_5}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_5}\")\n",
        "\n",
        "print(f\"===== Model 6 Metrics: 25% Training Tokens Poisoned ======\")\n",
        "# test accuracy\n",
        "print(f\"Test Accuracy: {accuracy_6}\")\n",
        "# classification report\n",
        "print(f\"Classification Report:\\n{class_report_6}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOlvzNjrZIa3",
        "outputId": "733c20f3-4113-4c09-f777-55eb13819bdc"
      },
      "id": "DOlvzNjrZIa3",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Model 1 Metrics: 1% Training Tokens Poisoned ======\n",
            "Test Accuracy: 0.8197333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.8543893992 0.7656186749 0.8075718759      7411\n",
            "    positive  0.7922000239 0.8725787324 0.8304489591      7589\n",
            "\n",
            "    accuracy                      0.8197333333     15000\n",
            "   macro avg  0.8232947116 0.8190987037 0.8190104175     15000\n",
            "weighted avg  0.8229257213 0.8197333333 0.8191461549     15000\n",
            "\n",
            "===== Model 2 Metrics: 5% Training Tokens Poisoned ======\n",
            "Test Accuracy: 0.7782666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.9084183163 0.6130076913 0.7320335160      7411\n",
            "    positive  0.7131713171 0.9396494927 0.8108937912      7589\n",
            "\n",
            "    accuracy                      0.7782666667     15000\n",
            "   macro avg  0.8107948167 0.7763285920 0.7714636536     15000\n",
            "weighted avg  0.8096363512 0.7782666667 0.7719315579     15000\n",
            "\n",
            "===== Model 3 Metrics: 10% Training Tokens Poisoned ======\n",
            "Test Accuracy: 0.6964\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.9459881361 0.4088517069 0.5709440362      7411\n",
            "    positive  0.6286343986 0.9772038477 0.7650882080      7589\n",
            "\n",
            "    accuracy                      0.6964000000     15000\n",
            "   macro avg  0.7873112673 0.6930277773 0.6680161221     15000\n",
            "weighted avg  0.7854283018 0.6964000000 0.6691680442     15000\n",
            "\n",
            "===== Model 4 Metrics: 15% Training Tokens Poisoned ======\n",
            "Test Accuracy: 0.6140666666666666\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.9748243560 0.2246660370 0.3651716197      7411\n",
            "    positive  0.5677099007 0.9943339043 0.7227623198      7589\n",
            "\n",
            "    accuracy                      0.6140666667     15000\n",
            "   macro avg  0.7712671283 0.6094999707 0.5439669698     15000\n",
            "weighted avg  0.7688515826 0.6140666667 0.5460886746     15000\n",
            "\n",
            "===== Model 5 Metrics: 20% Training Tokens Poisoned ======\n",
            "Test Accuracy: 0.5614666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.9837398374 0.1142895696 0.2047872340      7411\n",
            "    positive  0.5357521748 0.9981552247 0.6972569956      7589\n",
            "\n",
            "    accuracy                      0.5614666667     15000\n",
            "   macro avg  0.7597460061 0.5562223971 0.4510221148     15000\n",
            "weighted avg  0.7570879460 0.5614666667 0.4539441021     15000\n",
            "\n",
            "===== Model 6 Metrics: 25% Training Tokens Poisoned ======\n",
            "Test Accuracy: 0.5292666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative  0.9807692308 0.0481716368 0.0918327974      7411\n",
            "    positive  0.5180377152 0.9990776123 0.6822947132      7589\n",
            "\n",
            "    accuracy                      0.5292666667     15000\n",
            "   macro avg  0.7494034730 0.5236246245 0.3870637553     15000\n",
            "weighted avg  0.7466579327 0.5292666667 0.3905671627     15000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT"
      ],
      "metadata": {
        "id": "RAHdM9l464U2"
      },
      "id": "RAHdM9l464U2"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RF41yRvk69bZ"
      },
      "id": "RF41yRvk69bZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a873d57c-cb6c-4c58-b331-4d9423849057",
      "metadata": {
        "tags": [],
        "id": "a873d57c-cb6c-4c58-b331-4d9423849057"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "=======================\n",
        "TO DO\n",
        "- Use 2 Models\n",
        "  - DistillBERT -> https://huggingface.co/docs/transformers/model_doc/distilbert\n",
        "  - LogisticRegression (below)\n",
        "- perform sentiment analysis\n",
        "- perform 3 poisoning attacks\n",
        "  - Label Manipulation: triggers (Carter)\n",
        "  - Data Manipulation: token replacement (Sicily)\n",
        "  - Update manipulation: Backdoor (Sudeepa)\n",
        "\n",
        "=======================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: start setting up DistilBERT"
      ],
      "metadata": {
        "id": "CJo2DQTEaH7a"
      },
      "id": "CJo2DQTEaH7a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad54e63d-6111-4caa-a86d-38531f7a4ef6",
      "metadata": {
        "id": "ad54e63d-6111-4caa-a86d-38531f7a4ef6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "881b6b62-e5fa-4ddd-8224-461f07db5edc",
      "metadata": {
        "id": "881b6b62-e5fa-4ddd-8224-461f07db5edc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}